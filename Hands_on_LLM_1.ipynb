{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7f8fc3ad",
      "metadata": {
        "id": "7f8fc3ad"
      },
      "source": [
        "# Intro\n",
        "\n",
        "In this tutorial we will be exploring in-context learning for LLM using OpenAI's and Cohere's API.\n",
        "\n",
        "For illustration, we will look into the task of Natural Language Inference (NLI). As dataset, we will use the multi-genre dataset [MNLI](https://gluebenchmark.com/) in the GLUE benchmark, available in [huggingface](https://huggingface.co/datasets/glue).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc34fcb",
      "metadata": {
        "id": "5cc34fcb"
      },
      "source": [
        "# Preparing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install cohere\n",
        "!pip install openai\n",
        "!pip install numpy seaborn pandas sklearn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zliHSRoqfk-L",
        "outputId": "f16e9761-395a-4a5c-cf4d-42f1bdffc2c9"
      },
      "id": "zliHSRoqfk-L",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.8/dist-packages (3.8.0)\n",
            "Requirement already satisfied: urllib3~=1.26 in /usr/local/lib/python3.8/dist-packages (from cohere) (1.26.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from cohere) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.26.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.22.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.5.3)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=b0def3e81737c8aaeb824817a87d2db51bd5cffced4d21d681a2681c0004a9cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import cohere\n",
        "from cohere import CohereError\n",
        "import openai\n",
        "\n",
        "import pdb"
      ],
      "metadata": {
        "id": "4p8t4TbPhGbA"
      },
      "id": "4p8t4TbPhGbA",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset"
      ],
      "metadata": {
        "id": "tirx21_jhATe"
      },
      "id": "tirx21_jhATe"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0e073a05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "dba881a1dbf546b7b81b3c2fb1568f10",
            "e115429f48994097a07ad7cf8935c67f",
            "0322f546ca444f75b794833015d42e13",
            "b605419f7fe44b50b6ed2362b4a77759",
            "93a2e87dbd3a4dd0be5943050c869880",
            "5ef544522c7d4f2f80c4db6913909462",
            "122b1aecdddf49bf9fd96786745d0ee5",
            "86b5f62f8e9f405ab7b247b9233e07e0",
            "7ec3f4dfbf874215946bac26c5ba5340",
            "4b0cdeb1567341398ef6faad45575185",
            "0b5f8865c4764fae83b2b646ffd368ec"
          ]
        },
        "id": "0e073a05",
        "outputId": "61b2cfe6-1ed4-4714-a2b3-50cf54343267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dba881a1dbf546b7b81b3c2fb1568f10"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset(\"glue\", 'mnli')\n",
        "train = dataset['train']\n",
        "dev = dataset['validation_matched']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check some examples"
      ],
      "metadata": {
        "id": "LISGguA8hjrR"
      },
      "id": "LISGguA8hjrR"
    },
    {
      "cell_type": "code",
      "source": [
        "# entailment (0), neutral (1), contradiction (2).\n",
        "LABEL_NAMES = {\n",
        "    0: \"entailment\",\n",
        "    1: \"neutral\",\n",
        "    2: \"contradiction\"\n",
        "}\n",
        "\n",
        "for idx in [0,1,9]:\n",
        "  # print(train[idx])\n",
        "  print(\"[premise]\",train[idx][\"premise\"])\n",
        "  print(\"[hypothesis]\",train[idx][\"hypothesis\"])\n",
        "  print(\"[label]\",LABEL_NAMES[train[idx][\"label\"]])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPlSNLyXdud0",
        "outputId": "899e192d-e1de-499c-afd2-5b787f920fa5"
      },
      "id": "IPlSNLyXdud0",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[premise] Conceptually cream skimming has two basic dimensions - product and geography.\n",
            "[hypothesis] Product and geography are what make cream skimming work. \n",
            "[label] neutral\n",
            "\n",
            "[premise] you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him\n",
            "[hypothesis] You lose the things to the following level if the people recall.\n",
            "[label] entailment\n",
            "\n",
            "[premise] At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\n",
            "[hypothesis] Place des Vosges is constructed entirely of gray marble.\n",
            "[label] contradiction\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac0c7875",
      "metadata": {
        "id": "ac0c7875"
      },
      "source": [
        "# Using Large Language Models (LLMs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI's GPT-3\n",
        "\n",
        "In order to use the API you should create an account [here](https://openai.com/api/). Create an API key and paste it below.\n",
        "We will be using 'text-davince-003', and you can play with directly [here](https://https://platform.openai.com/playground/p/default-summarize?model=text-davinci-003)\n",
        "\n"
      ],
      "metadata": {
        "id": "AajNtOMBffKn"
      },
      "id": "AajNtOMBffKn"
    },
    {
      "cell_type": "code",
      "source": [
        "openai_apikey=\"\"\n",
        "openai.api_key = openai_apikey"
      ],
      "metadata": {
        "id": "rutSDyfZh3Ho"
      },
      "id": "rutSDyfZh3Ho",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell\"\n",
        "\n",
        "openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrYXDXQTioS2",
        "outputId": "5fc27435-a5a5-40e0-cd07-71a33ca7a4b4"
      },
      "id": "PrYXDXQTioS2",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-6oXaM85uGPeBe7ozkXKwM9QloIC89 at 0x7f756d1164a0> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \", nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\\n\\nIt had a perfectly round door like a porthole, painted green, with a shiny yellow brass knob in the exact middle. The\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1677503522,\n",
              "  \"id\": \"cmpl-6oXaM85uGPeBe7ozkXKwM9QloIC89\",\n",
              "  \"model\": \"text-davinci-003\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 64,\n",
              "    \"prompt_tokens\": 32,\n",
              "    \"total_tokens\": 96\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cohere\n",
        "\n",
        "Sign-up to cohere.com using this [link](https://dashboard.cohere.ai/welcome/register?utm_source=cohere-owned&utm_medium=event&utm_campaign=matthias-course).\n",
        "Retrieve your API key and copy this to the variable below.\n",
        "\n",
        "Find more documentation on the parameters [here](https://docs.cohere.ai/reference/generate).\n"
      ],
      "metadata": {
        "id": "DtMD3lmFhuoD"
      },
      "id": "DtMD3lmFhuoD"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fbd55a31",
      "metadata": {
        "id": "fbd55a31"
      },
      "outputs": [],
      "source": [
        "\n",
        "co_apikey=\"\"\n",
        "co = cohere.Client(co_apikey)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7a2bce1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a2bce1c",
        "outputId": "84dad15c-dabd-47aa-facf-e04041d62007"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cohere.Generations {\n",
              "\tid: None\n",
              "\tgenerations: [cohere.Generation {\n",
              "\tid: 654a88af-4f01-4e53-b814-c2a1a903692a\n",
              "\ttext: , nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\"\n",
              "\n",
              "And so begins one of the most beloved stories in history. Now a major motion picture from director Peter Jackson, Academy Award®-\n",
              "\tlikelihood: None\n",
              "\ttoken_likelihoods: None\n",
              "}]\n",
              "\treturn_likelihoods: None\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "prompt = \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell\"\n",
        "co.generate(prompt,\n",
        "            model=\"xlarge\",\n",
        "            max_tokens=64,\n",
        "            temperature=0.7,\n",
        "            num_generations=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d416e2",
      "metadata": {
        "id": "26d416e2"
      },
      "source": [
        "## In-context learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_predictions(preds):\n",
        "  res = []\n",
        "  for pred in preds:\n",
        "    pred = pred.lower()\n",
        "    if \"false\" in pred or \"incorrect\" in pred: res.append(2)\n",
        "    elif \"true\" in pred or \"correct\" in pred: res.append(0)\n",
        "    else:              res.append(1)\n",
        "  return res\n",
        "\n",
        "def evaluate_accuracy(gold_labels,predicted_labels):\n",
        "  nn = len(gold_labels)\n",
        "  if nn==0: return 0.0\n",
        "  return sum(x==y for x,y in zip(gold_labels,predicted_labels)) / nn"
      ],
      "metadata": {
        "id": "lVZ-g4Ls_Kc4"
      },
      "id": "lVZ-g4Ls_Kc4",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = np.arange(len(dev),dtype=int)\n",
        "np.random.shuffle(idxs)\n",
        "\n",
        "num_samples = 20\n",
        "dev_sample = [dev[int(i)] for i in idxs[:num_samples]]\n",
        "\n",
        "\n",
        "task_description = \"Determine if a hypothesis sentence is True, False, or Undetermined, given a premise sentence.\""
      ],
      "metadata": {
        "id": "oaAM2pikIV2O"
      },
      "id": "oaAM2pikIV2O",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot ICL"
      ],
      "metadata": {
        "id": "8hoLcb2T9uj7"
      },
      "id": "8hoLcb2T9uj7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cohere API\n",
        "predictions = []\n",
        "\n",
        "for item in dev_sample:\n",
        "  _input = f\"task: {task_description}\\npremise: {item['premise']}\\nhypothesis: {item['hypothesis']}\\nanswer:\"\n",
        "  output = co.generate(_input,\n",
        "                model=\"xlarge\",\n",
        "                max_tokens=10,\n",
        "                temperature=1.0,\n",
        "                num_generations=1)[0]\n",
        "  resp = output.text.strip(\" \")\n",
        "  predictions.append(resp)\n",
        "#"
      ],
      "metadata": {
        "id": "NL7U3ysn-3RG"
      },
      "id": "NL7U3ysn-3RG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API\n",
        "predictions = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "  _input = f\"task: {task_description}\\npremise: {train[i]['premise']}\\nhypothesis: {train[i]['hypothesis']}\\nanswer:\"\n",
        "  output = openai.Completion.create(\n",
        "              model=\"text-davinci-003\",\n",
        "              prompt=_input,\n",
        "              temperature=1.0,\n",
        "              max_tokens=10,\n",
        "              top_p=1.0,\n",
        "              frequency_penalty=0.0,\n",
        "              presence_penalty=0.0\n",
        "            )\n",
        "  \n",
        "  print(output[\"choices\"][0][\"text\"])\n",
        "  resp = output[\"choices\"][0][\"text\"].strip(\" \")\n",
        "  predictions.append(resp)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ETtEYQ6GDnf",
        "outputId": "10019257-a2db-4b9e-9a22-2c74d61b4886"
      },
      "id": "2ETtEYQ6GDnf",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " False\n",
            " False\n",
            " True\n",
            " False\n",
            " True\n",
            " False\n",
            " False\n",
            " False\n",
            " True\n",
            " True\n",
            " Undetermined\n",
            " True\n",
            " True\n",
            " False\n",
            " False\n",
            " False\n",
            " False\n",
            " Undetermined\n",
            " False\n",
            " True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "\n",
        "gold = [item[\"label\"] for item in dev_sample]\n",
        "acc = evaluate_accuracy(gold,normalize_predictions(predictions))\n",
        "print(\"[Accuracy]\",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwSK4UxZHsmF",
        "outputId": "289e32d3-67b5-45ae-8f4d-5b8af3807612"
      },
      "id": "zwSK4UxZHsmF",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Accuracy] 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gold)\n",
        "print(normalize_predictions(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePwL_Kn7Kutu",
        "outputId": "1bfd227b-90d2-41bc-f930-63bd66ab11fd"
      },
      "id": "ePwL_Kn7Kutu",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 0, 2, 0]\n",
            "[2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 1, 2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot in-context learning"
      ],
      "metadata": {
        "id": "IL40_9sdJEZQ"
      },
      "id": "IL40_9sdJEZQ"
    },
    {
      "cell_type": "markdown",
      "id": "fee0ea65",
      "metadata": {
        "id": "fee0ea65"
      },
      "source": [
        "Few-shot in-context learning consists in providing some examples, structured in a certain way (\"prompt engineering\") and leverage the fact that LLM are good in pattern-matching."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = np.arange(len(train),dtype=int)\n",
        "np.random.shuffle(idxs)\n",
        "train = [train[int(i)] for i in idxs]\n",
        "\n",
        "train_sample = []\n",
        "for lab in LABEL_NAMES.keys():\n",
        "  for item in train:\n",
        "    if item[\"label\"] == lab:\n",
        "      train_sample.append(item)\n",
        "      break\n",
        "\n",
        "exemplars = \"\\n\".join([f\"premise: {titem['premise']}\\nhypothesis: {titem['hypothesis']}\\nanswer: {label_idx_to_token[titem['label']]}\" for titem in train_sample])\n",
        "prompt = f\"task: {task_description}\\n{exemplars}\""
      ],
      "metadata": {
        "id": "SORICv5w9zAm"
      },
      "id": "SORICv5w9zAm",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDribd9DOm4C",
        "outputId": "95480f80-e3c2-4f1e-d7a1-81cb2046fbf7"
      },
      "id": "vDribd9DOm4C",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task: Determine if a hypothesis sentence is True, False, or Undetermined, given a premise sentence.\n",
            "premise: The DSPB will be asked to provide any additional written information it wishes to be considered to assist the LSC President in fully and fairly entertaining all concerns and objections.\n",
            "hypothesis: The LSC President may receive assistance from the DSPB.\n",
            "answer: True\n",
            "premise: His interest was absorbed by the adults.\n",
            "hypothesis: The adults absorbed all interest he had in the ship.\n",
            "answer: Undetermined\n",
            "premise: yes i i felt that it certainly was i mean i was smarter than most of the people that i was working for and uh you know every time something new came up i was explaining it to them and uh i had\n",
            "hypothesis: I am not very smart.\n",
            "answer: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_idx_to_token = {\n",
        "    2: \"False\",\n",
        "    0: \"True\",\n",
        "    1: \"Undetermined\",\n",
        "}\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for item in dev_sample:\n",
        "  _input = f\"{prompt}\\npremise: {item['premise']}\\nhypothesis: {item['hypothesis']}\\nanswer:\"\n",
        "  \n",
        "  output = openai.Completion.create(\n",
        "              model=\"text-davinci-003\",\n",
        "              prompt=_input,\n",
        "              temperature=1.0,\n",
        "              max_tokens=10,\n",
        "              top_p=1.0,\n",
        "              frequency_penalty=0.0,\n",
        "              presence_penalty=0.0\n",
        "            )\n",
        "  print(output[\"choices\"][0][\"text\"])\n",
        "  resp = output[\"choices\"][0][\"text\"].strip(\" \")\n",
        "  predictions.append(resp)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "qzZbn4XzJKkU",
        "outputId": "c1d7fd66-4666-4c7b-d674-7934d722b004"
      },
      "id": "qzZbn4XzJKkU",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " False\n",
            " True\n",
            " True\n",
            " False\n",
            " False\n",
            " Undetermined\n",
            " True\n",
            " True\n",
            " True\n",
            " True\n",
            " True\n",
            " True\n",
            " False\n",
            " True\n",
            " False\n",
            " False\n",
            " False\n",
            " Undetermined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-a7e6349bd34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0m_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{prompt}\\npremise: {item['premise']}\\nhypothesis: {item['hypothesis']}\\nanswer:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   output = openai.Completion.create(\n\u001b[0m\u001b[1;32m     13\u001b[0m               \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             return (\n\u001b[0;32m--> 619\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-text-davinci-003 in organization org-3h04bH8ZtuUbsfRIblEfbEVC on requests per min. Limit: 60.000000 / min. Current: 70.000000 / min. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "\n",
        "gold = [item[\"label\"] for item in dev_sample]\n",
        "acc = evaluate_accuracy(gold,normalize_predictions(predictions))\n",
        "print(\"[Accuracy]\",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SkG_CcaMp7A",
        "outputId": "4172607d-17c8-4ab2-ce71-bd45f6692153"
      },
      "id": "7SkG_CcaMp7A",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Accuracy] 0.65\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dba881a1dbf546b7b81b3c2fb1568f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e115429f48994097a07ad7cf8935c67f",
              "IPY_MODEL_0322f546ca444f75b794833015d42e13",
              "IPY_MODEL_b605419f7fe44b50b6ed2362b4a77759"
            ],
            "layout": "IPY_MODEL_93a2e87dbd3a4dd0be5943050c869880"
          }
        },
        "e115429f48994097a07ad7cf8935c67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ef544522c7d4f2f80c4db6913909462",
            "placeholder": "​",
            "style": "IPY_MODEL_122b1aecdddf49bf9fd96786745d0ee5",
            "value": "100%"
          }
        },
        "0322f546ca444f75b794833015d42e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b5f62f8e9f405ab7b247b9233e07e0",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ec3f4dfbf874215946bac26c5ba5340",
            "value": 5
          }
        },
        "b605419f7fe44b50b6ed2362b4a77759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0cdeb1567341398ef6faad45575185",
            "placeholder": "​",
            "style": "IPY_MODEL_0b5f8865c4764fae83b2b646ffd368ec",
            "value": " 5/5 [00:00&lt;00:00, 147.92it/s]"
          }
        },
        "93a2e87dbd3a4dd0be5943050c869880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef544522c7d4f2f80c4db6913909462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122b1aecdddf49bf9fd96786745d0ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86b5f62f8e9f405ab7b247b9233e07e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec3f4dfbf874215946bac26c5ba5340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b0cdeb1567341398ef6faad45575185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5f8865c4764fae83b2b646ffd368ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}